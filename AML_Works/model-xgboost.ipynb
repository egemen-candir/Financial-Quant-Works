{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "882fe977",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, roc_curve\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"AML DETECTION WITH XGBOOST\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# 1. Load data\n",
    "df = pd.read_csv('HI-Small_Trans.csv')\n",
    "print(f\"Data loaded: {df.shape[0]:,} transactions\")\n",
    "print(f\"Target distribution:\\n{df['Is Laundering'].value_counts()}\")\n",
    "\n",
    "# 2. Feature Engineering (Same as Logistic Regression)\n",
    "print(\"\\nCreating AML-specific features...\")\n",
    "\n",
    "# Convert timestamp\n",
    "df['Timestamp'] = pd.to_datetime(df['Timestamp'])\n",
    "df['hour'] = df['Timestamp'].dt.hour\n",
    "df['day_of_week'] = df['Timestamp'].dt.dayofweek\n",
    "df['is_weekend'] = (df['day_of_week'] >= 5).astype(int)\n",
    "\n",
    "# Amount-based features\n",
    "df['amount_difference'] = abs(df['Amount Received'] - df['Amount Paid'])\n",
    "df['amount_ratio'] = df['Amount Received'] / (df['Amount Paid'] + 1e-8)\n",
    "df['log_amount_received'] = np.log1p(df['Amount Received'])\n",
    "df['log_amount_paid'] = np.log1p(df['Amount Paid'])\n",
    "\n",
    "# Currency features\n",
    "df['currency_mismatch'] = (df['Receiving Currency'] != df['Payment Currency']).astype(int)\n",
    "\n",
    "# Bank features\n",
    "df['same_bank'] = (df['From Bank'] == df['To Bank']).astype(int)\n",
    "\n",
    "# Account features (encode account patterns)\n",
    "le_account = LabelEncoder()\n",
    "le_account1 = LabelEncoder()\n",
    "le_payment_format = LabelEncoder()\n",
    "le_recv_currency = LabelEncoder()\n",
    "le_pay_currency = LabelEncoder()\n",
    "\n",
    "df['account_encoded'] = le_account.fit_transform(df['Account'].astype(str))\n",
    "df['account1_encoded'] = le_account1.fit_transform(df['Account.1'].astype(str))\n",
    "df['payment_format_encoded'] = le_payment_format.fit_transform(df['Payment Format'])\n",
    "df['recv_currency_encoded'] = le_recv_currency.fit_transform(df['Receiving Currency'])\n",
    "df['pay_currency_encoded'] = le_pay_currency.fit_transform(df['Payment Currency'])\n",
    "\n",
    "# Risk indicators\n",
    "df['round_amount_received'] = (df['Amount Received'] % 1000 == 0).astype(int)\n",
    "df['round_amount_paid'] = (df['Amount Paid'] % 1000 == 0).astype(int)\n",
    "df['high_risk_hours'] = ((df['hour'] < 6) | (df['hour'] > 22)).astype(int)\n",
    "\n",
    "# Additional XGBoost-friendly features (can capture interactions automatically)\n",
    "df['bank_pair'] = df['From Bank'].astype(str) + '_' + df['To Bank'].astype(str)\n",
    "df['bank_pair_encoded'] = LabelEncoder().fit_transform(df['bank_pair'])\n",
    "\n",
    "# 3. Select features for XGBoost\n",
    "feature_columns = [\n",
    "    'From Bank', 'To Bank', 'bank_pair_encoded',\n",
    "    'Amount Received', 'Amount Paid', \n",
    "    'log_amount_received', 'log_amount_paid',\n",
    "    'amount_difference', 'amount_ratio',\n",
    "    'currency_mismatch', 'same_bank',\n",
    "    'hour', 'day_of_week', 'is_weekend', 'high_risk_hours',\n",
    "    'round_amount_received', 'round_amount_paid',\n",
    "    'payment_format_encoded', 'recv_currency_encoded', 'pay_currency_encoded',\n",
    "    'account_encoded', 'account1_encoded'\n",
    "]\n",
    "\n",
    "X = df[feature_columns].copy()\n",
    "y = df['Is Laundering'].copy()\n",
    "\n",
    "print(f\"Features selected: {len(feature_columns)}\")\n",
    "print(f\"Class balance - Legitimate: {(y==0).sum():,}, Laundering: {(y==1).sum():,}\")\n",
    "\n",
    "# 4. Handle missing values and infinite values\n",
    "X = X.replace([np.inf, -np.inf], np.nan)\n",
    "X = X.fillna(X.median())\n",
    "\n",
    "# 5. Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(f\"\\nTrain set: {X_train.shape[0]:,} transactions\")\n",
    "print(f\"Test set: {X_test.shape[0]:,} transactions\")\n",
    "\n",
    "# 6. Calculate scale_pos_weight for class imbalance\n",
    "num_negative = (y_train == 0).sum()\n",
    "num_positive = (y_train == 1).sum()\n",
    "scale_pos_weight = num_negative / num_positive\n",
    "\n",
    "print(f\"\\nClass imbalance handling:\")\n",
    "print(f\"  â€¢ Negative samples: {num_negative:,}\")\n",
    "print(f\"  â€¢ Positive samples: {num_positive:,}\")\n",
    "print(f\"  â€¢ scale_pos_weight: {scale_pos_weight:.2f}\")\n",
    "\n",
    "# 7. Train XGBoost Model\n",
    "print(\"\\nTraining XGBoost...\")\n",
    "\n",
    "# XGBoost hyperparameters as per markdown guidance\n",
    "xgb_model = xgb.XGBClassifier(\n",
    "    n_estimators=500,\n",
    "    learning_rate=0.05,\n",
    "    max_depth=6,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    scale_pos_weight=scale_pos_weight,\n",
    "    eval_metric='auc',\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    "    early_stopping_rounds=50\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "xgb_model.fit(\n",
    "    X_train, y_train,\n",
    "    eval_set=[(X_test, y_test)],\n",
    "    verbose=False\n",
    ")\n",
    "\n",
    "# 8. Make predictions\n",
    "y_pred = xgb_model.predict(X_test)\n",
    "y_pred_proba = xgb_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# 9. Evaluate performance\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"XGBOOST MODEL PERFORMANCE\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "auc_score = roc_auc_score(y_test, y_pred_proba)\n",
    "print(f\"\\nROC AUC Score: {auc_score:.4f}\")\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(f\"\\nConfusion Matrix:\")\n",
    "print(f\"True Negatives: {cm[0,0]:,}\")\n",
    "print(f\"False Positives: {cm[0,1]:,}\")\n",
    "print(f\"False Negatives: {cm[1,0]:,}\")\n",
    "print(f\"True Positives: {cm[1,1]:,}\")\n",
    "\n",
    "# Calculate precision and recall for minority class\n",
    "precision = cm[1,1] / (cm[1,1] + cm[0,1]) if (cm[1,1] + cm[0,1]) > 0 else 0\n",
    "recall = cm[1,1] / (cm[1,1] + cm[1,0]) if (cm[1,1] + cm[1,0]) > 0 else 0\n",
    "f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "\n",
    "print(f\"\\nMinority Class (Laundering) Metrics:\")\n",
    "print(f\"  â€¢ Precision: {precision:.4f}\")\n",
    "print(f\"  â€¢ Recall: {recall:.4f}\")\n",
    "print(f\"  â€¢ F1-Score: {f1:.4f}\")\n",
    "\n",
    "# 10. Feature Importance\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"FEATURE IMPORTANCE (TOP 15)\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Get feature importance\n",
    "feature_importance = pd.DataFrame({\n",
    "    'feature': feature_columns,\n",
    "    'importance': xgb_model.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "print(\"\\nTop 15 Most Important Features:\")\n",
    "for i, (_, row) in enumerate(feature_importance.head(15).iterrows()):\n",
    "    print(f\"{i+1:2d}. {row['feature']:<25} (importance: {row['importance']:.4f})\")\n",
    "\n",
    "# 11. Threshold Analysis\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"THRESHOLD ANALYSIS\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "thresholds = [0.1, 0.3, 0.5, 0.7, 0.9]\n",
    "print(f\"\\nðŸš¨ ALERT VOLUME AT DIFFERENT RISK THRESHOLDS:\")\n",
    "\n",
    "threshold_results = []\n",
    "for threshold in thresholds:\n",
    "    thresh_pred = (y_pred_proba > threshold).astype(int)\n",
    "    alerts = thresh_pred.sum()\n",
    "    alert_rate = alerts / len(y_test) * 100\n",
    "    \n",
    "    # Calculate metrics for this threshold\n",
    "    thresh_cm = confusion_matrix(y_test, thresh_pred)\n",
    "    thresh_precision = thresh_cm[1,1] / (thresh_cm[1,1] + thresh_cm[0,1]) if (thresh_cm[1,1] + thresh_cm[0,1]) > 0 else 0\n",
    "    thresh_recall = thresh_cm[1,1] / (thresh_cm[1,1] + thresh_cm[1,0]) if (thresh_cm[1,1] + thresh_cm[1,0]) > 0 else 0\n",
    "    \n",
    "    print(f\"  â€¢ Threshold {threshold}: {alerts:,} alerts ({alert_rate:.2f}%) | Precision: {thresh_precision:.3f} | Recall: {thresh_recall:.3f}\")\n",
    "    \n",
    "    threshold_results.append({\n",
    "        'threshold': threshold,\n",
    "        'alerts': alerts,\n",
    "        'alert_rate': alert_rate,\n",
    "        'precision': thresh_precision,\n",
    "        'recall': thresh_recall\n",
    "    })\n",
    "\n",
    "# 12. Visualizations\n",
    "plt.figure(figsize=(15, 10))\n",
    "\n",
    "# ROC Curve\n",
    "plt.subplot(2, 3, 1)\n",
    "fpr, tpr, _ = roc_curve(y_test, y_pred_proba)\n",
    "plt.plot(fpr, tpr, color='blue', linewidth=2, label=f'XGBoost (AUC = {auc_score:.3f})')\n",
    "plt.plot([0, 1], [0, 1], color='red', linestyle='--', label='Random Classifier')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve - XGBoost AML Detection')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Feature Importance\n",
    "plt.subplot(2, 3, 2)\n",
    "top_features = feature_importance.head(10)\n",
    "plt.barh(range(len(top_features)), top_features['importance'])\n",
    "plt.yticks(range(len(top_features)), top_features['feature'])\n",
    "plt.xlabel('Feature Importance')\n",
    "plt.title('Top 10 Feature Importance')\n",
    "plt.gca().invert_yaxis()\n",
    "\n",
    "# Threshold Analysis - Alert Volume\n",
    "plt.subplot(2, 3, 3)\n",
    "thresh_df = pd.DataFrame(threshold_results)\n",
    "plt.plot(thresh_df['threshold'], thresh_df['alert_rate'], 'o-', color='orange')\n",
    "plt.xlabel('Risk Threshold')\n",
    "plt.ylabel('Alert Rate (%)')\n",
    "plt.title('Alert Volume by Threshold')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Precision-Recall by Threshold\n",
    "plt.subplot(2, 3, 4)\n",
    "plt.plot(thresh_df['threshold'], thresh_df['precision'], 'o-', label='Precision', color='green')\n",
    "plt.plot(thresh_df['threshold'], thresh_df['recall'], 'o-', label='Recall', color='red')\n",
    "plt.xlabel('Risk Threshold')\n",
    "plt.ylabel('Score')\n",
    "plt.title('Precision vs Recall by Threshold')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Prediction Distribution\n",
    "plt.subplot(2, 3, 5)\n",
    "plt.hist(y_pred_proba[y_test == 0], bins=50, alpha=0.7, label='Legitimate', density=True)\n",
    "plt.hist(y_pred_proba[y_test == 1], bins=50, alpha=0.7, label='Laundering', density=True)\n",
    "plt.xlabel('Predicted Probability')\n",
    "plt.ylabel('Density')\n",
    "plt.title('Prediction Distribution')\n",
    "plt.legend()\n",
    "\n",
    "# XGBoost built-in feature importance plot\n",
    "plt.subplot(2, 3, 6)\n",
    "xgb.plot_importance(xgb_model, max_num_features=10, importance_type='weight', ax=plt.gca())\n",
    "plt.title('XGBoost Feature Importance (Weight)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 13. Business Interpretation\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"BUSINESS INTERPRETATION\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "total_transactions = len(y_test)\n",
    "flagged_transactions = (y_pred_proba > 0.5).sum()\n",
    "flagged_rate = flagged_transactions / total_transactions * 100\n",
    "\n",
    "print(f\"\\nðŸ“Š OPERATIONAL METRICS:\")\n",
    "print(f\"  â€¢ Total transactions analyzed: {total_transactions:,}\")\n",
    "print(f\"  â€¢ Transactions flagged as suspicious: {flagged_transactions:,} ({flagged_rate:.2f}%)\")\n",
    "print(f\"  â€¢ Model accuracy: {(y_pred == y_test).mean()*100:.2f}%\")\n",
    "print(f\"  â€¢ AUC Score: {auc_score:.4f}\")\n",
    "\n",
    "print(f\"\\nðŸ’¡ KEY INSIGHTS:\")\n",
    "top_risk_factor = feature_importance.iloc[0]\n",
    "print(f\"  â€¢ Most predictive feature: {top_risk_factor['feature']} (importance: {top_risk_factor['importance']:.4f})\")\n",
    "print(f\"  â€¢ XGBoost automatically captures feature interactions\")\n",
    "print(f\"  â€¢ Model handles class imbalance with scale_pos_weight = {scale_pos_weight:.2f}\")\n",
    "\n",
    "# Optimal threshold recommendation\n",
    "optimal_idx = thresh_df[thresh_df['recall'] >= 0.8]['precision'].idxmax()\n",
    "if not pd.isna(optimal_idx):\n",
    "    optimal_threshold = thresh_df.loc[optimal_idx, 'threshold']\n",
    "    optimal_precision = thresh_df.loc[optimal_idx, 'precision']\n",
    "    optimal_recall = thresh_df.loc[optimal_idx, 'recall']\n",
    "    print(f\"  â€¢ Recommended threshold: {optimal_threshold} (Precision: {optimal_precision:.3f}, Recall: {optimal_recall:.3f})\")\n",
    "\n",
    "print(f\"\\nðŸŽ¯ ADVANTAGES OVER LOGISTIC REGRESSION:\")\n",
    "print(f\"  â€¢ No feature scaling required\")\n",
    "print(f\"  â€¢ Automatic interaction detection\")\n",
    "print(f\"  â€¢ Better handling of non-linear patterns\")\n",
    "print(f\"  â€¢ Built-in feature importance ranking\")\n",
    "print(f\"  â€¢ Early stopping prevents overfitting\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-projects",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
